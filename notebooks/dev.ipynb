{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "Collecting prawcore<3,>=2.4\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Collecting update_checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.0.4)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Installing collected packages: prawcore, update-checker, praw, urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed praw-7.8.1 prawcore-2.4.0 update-checker-0.18.0 urllib3-1.25.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "conda 4.12.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "selenium 4.27.1 requires urllib3[socks]<3,>=1.26, but you'll have urllib3 1.25.11 which is incompatible.\n",
      "google-api-core 2.10.0 requires protobuf<5.0.0dev,>=3.20.1, but you'll have protobuf 3.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monke\\\\Repos\\\\eav-llm-monitor\\\\notebooks'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_creds_uri = '..\\\\src\\\\utils\\\\reddit_creds.json'\n",
    "# os.listdir(reddit_creds_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_creds = io_utils.read_json(reddit_creds_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['REDDIT_CLIENT_ID', 'REDDIT_SECRET', 'REDDIT_USER_AGENT'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_creds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id = reddit_creds['REDDIT_CLIENT_ID'],\n",
    "    client_secret = reddit_creds['REDDIT_SECRET'],\n",
    "    user_agent = reddit_creds['REDDIT_USER_AGENT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['rivian', 'electricvehicles', 'ElectricCars']\n",
    "# subreddits += ['CarRepair', 'autorepair', 'MechanicAdvice']\n",
    "# subreddits += ['DIYAutoRepair', 'AutoMechanics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['broke down', 'issue', 'charging problem', 'reliability', \"won't start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = 'rivian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'broke down'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in reddit.subreddit(sub).search(term, sort='new', limit = 100):\n",
    "    results.append({\n",
    "        'subreddit': sub,\n",
    "        'title': post.title,\n",
    "        'selftext': post.selftext,\n",
    "        'score': post.score,\n",
    "        'created_utc': datetime.fromtimestamp(post.created_utc),\n",
    "        'url': post.url,\n",
    "        'permalink': f\"https://www.reddit.com{post.permalink}\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subreddit': 'rivian',\n",
       " 'title': 'Leased 2 Rivians in March. Both are in the service center. It’s been hell.',\n",
       " 'selftext': 'So, my wife and I leased 2 Rivians to take advantage of the $200 off per month lease. I got the T, she got the S. My T broke down in the middle of the interstate with less than 350 miles on it. It’s been in the shop since early April, and they had to replace the 12v battery, ac compressor, and the pyrofuse(?) Not sure what that one is, but their target pickup date is next Wednesday. Their initial diagnosis was that they needed to replace the high voltage battery, but that’s been ruled out for now.\\n\\nWhen the T was in the center, they set me up with a rental. It was horrible. I got a loaner after complaining that I can’t drive the rental because I needed a truck for work. So since, I’ve been driving the T loaner, and the card key is a nightmare to use.\\n\\nThen I found some blue/green liquid under my wife’s S in the garage floor after she took it out for work. So I searched online and found stories where the car had to be towed to be serviced at the center. So I made a service claim and sent pictures. Lo and behold, they sent a tow truck to pick it up. No estimated date yet. And no loaner.\\n\\nNow we are regretting getting Rivians. Even after this whole thing gets fixed, still leaves a bad taste. \\n\\nI know cars can have problems and finding it out now rather than a year out is better, but not being able to drive my car that I’m paying for a month now is frustrating. \\n\\nAre we just bad luck or is this pretty common for new Rivians?',\n",
       " 'score': 180,\n",
       " 'created_utc': datetime.datetime(2025, 5, 9, 8, 28, 21),\n",
       " 'url': 'https://www.reddit.com/r/Rivian/comments/1kilamq/leased_2_rivians_in_march_both_are_in_the_service/',\n",
       " 'permalink': 'https://www.reddit.com/r/Rivian/comments/1kilamq/leased_2_rivians_in_march_both_are_in_the_service/'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 5, 9, 8, 28, 21)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2]['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime(2005, 6, 23, 0, 0, 0)\n",
    "y = datetime(2025, 5, 9, 8, 28, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y > x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = paths.get_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///C:/Users/monke/Repos/eav-llm-monitor'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.as_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/monke/Repos/eav-llm-monitor/data/raw/reddit_20250711_020056.csv')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths.get_data_raw_path() / f'reddit_{timestamp}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'{}{timestamp}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_datetime_fmt = '%Y%m%d_%H%M%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_reddit_timestamp():\n",
    "    \"\"\"Find the latest timestamp from the reddit raw data files\"\"\"\n",
    "    latest_data_csv = [csv for csv in os.listdir(paths.get_data_raw_path()) if 'reddit' in csv]\n",
    "    if len(latest_data_csv) == 0:\n",
    "        return None\n",
    "    latest_data_csv = max(latest_data_csv)\n",
    "    datetime_str = latest_data_csv.replace('reddit_raw_','').replace('.csv', '')\n",
    "    return datetime.strptime(datetime_str, data_datetime_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 7, 11, 2, 2, 51)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_latest_reddit_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reddit_raw_20250711_020251.csv']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[csv for csv in os.listdir(paths.get_data_raw_path()) if 'reddit' in csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250711_020251'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'reddit_raw_20250711_020251.csv'.replace('reddit_raw_','').replace('.csv', '')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 7, 11, 2, 2, 51)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(s, data_datetime_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['reddit_raw_20250701_020251.csv',\n",
    "'reddit_raw_20250706_020251.csv',\n",
    "'reddit_raw_20250715_020251.csv',\n",
    "'reddit_raw_20250711_020251.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit_raw_20250715_020251.csv'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-a48d8f8c12de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "max([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\src\\\\utils\\\\reddit_creds.json'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_creds_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/monke/Repos/eav-llm-monitor/src/utils/reddit_creds.json')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_creds_uri = paths.get_project_root() / 'src' / 'utils' / 'reddit_creds.json'\n",
    "reddit_creds_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching r/rivian for \"broke down\"...\n",
      "Searching r/rivian for \"issue\"...\n",
      "Searching r/rivian for \"charging problem\"...\n",
      "Searching r/rivian for \"reliability\"...\n",
      "Searching r/rivian for \"won’t start\"...\n",
      "Searching r/electricvehicles for \"broke down\"...\n",
      "Searching r/electricvehicles for \"issue\"...\n",
      "Searching r/electricvehicles for \"charging problem\"...\n",
      "Searching r/electricvehicles for \"reliability\"...\n",
      "Searching r/electricvehicles for \"won’t start\"...\n",
      "Searching r/ElectricCars for \"broke down\"...\n",
      "Searching r/ElectricCars for \"issue\"...\n",
      "Searching r/ElectricCars for \"charging problem\"...\n",
      "Searching r/ElectricCars for \"reliability\"...\n",
      "Searching r/ElectricCars for \"won’t start\"...\n",
      "Reddit finished scraping\n",
      "20250711_020251\n",
      "1045 results, saved as C:\\Users\\monke\\Repos\\eav-llm-monitor\\data\\raw\\reddit_raw_20250711_020251.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import io_utils\n",
    "from utils import paths\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\" Praw resources\n",
    "https://praw.readthedocs.io/en/stable/index.html\n",
    "https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html\n",
    "https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "\"\"\"\n",
    "\n",
    "# praw setup\n",
    "reddit_creds_uri = paths.get_project_root() / 'src' / 'utils' / 'reddit_creds.json'\n",
    "reddit_creds = io_utils.read_json(reddit_creds_uri)\n",
    "reddit = praw.Reddit(\n",
    "    client_id = reddit_creds['REDDIT_CLIENT_ID'],\n",
    "    client_secret = reddit_creds['REDDIT_SECRET'],\n",
    "    user_agent = reddit_creds['REDDIT_USER_AGENT']\n",
    ")\n",
    "\n",
    "data_datetime_fmt = '%Y%m%d_%H%M%S'\n",
    "\n",
    "def scrape_reddit(subreddits, search_terms, last_update=None, limit=100):\n",
    "    \"\"\"Scrapes various subreddits for various terms and returns as a df\"\"\"\n",
    "    if last_update is None:\n",
    "        last_update = datetime(2005, 6, 23, 0, 0, 0) # beginning of reddit\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        for term in search_terms:\n",
    "            print(f'Searching r/{sub} for \"{term}\"...')\n",
    "            for post in reddit.subreddit(sub).search(term, sort='new', limit=limit):\n",
    "                post_timestamp = datetime.fromtimestamp(post.created_utc)\n",
    "                if post_timestamp > last_update:\n",
    "                    results.append({\n",
    "                        'subreddit': sub,\n",
    "                        'title': post.title,\n",
    "                        'selftext': post.selftext,\n",
    "                        'score': post.score,\n",
    "                        'created_utc': post_timestamp,\n",
    "                        'url': post.url,\n",
    "                        'permalink': f\"https://www.reddit.com{post.permalink}\"\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def find_latest_reddit_timestamp():\n",
    "    \"\"\"Find the latest timestamp from the reddit raw data files\"\"\"\n",
    "    latest_data_csv = [csv for csv in os.listdir(paths.get_data_raw_path()) if 'reddit' in csv]\n",
    "    if len(latest_data_csv) == 0:\n",
    "        return None\n",
    "    latest_data_csv = max(latest_data_csv)\n",
    "    datetime_str = latest_data_csv.replace('reddit_raw_','').replace('.csv', '')\n",
    "    return datetime.strptime(datetime_str, data_datetime_fmt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    subreddits = ['rivian', 'electricvehicles', 'ElectricCars']\n",
    "    # subreddits += ['CarRepair', 'autorepair', 'MechanicAdvice']\n",
    "    # subreddits += ['DIYAutoRepair', 'AutoMechanics']\n",
    "    \n",
    "    search_terms = ['broke down', 'issue', 'charging problem', 'reliability', 'won’t start']\n",
    "    \n",
    "    df = scrape_reddit(subreddits, search_terms, last_update = find_latest_reddit_timestamp())\n",
    "    \n",
    "    timestamp = datetime.now().strftime(data_datetime_fmt)\n",
    "    filename = paths.get_data_raw_path() / f'reddit_raw_{timestamp}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    print('Reddit finished scraping')\n",
    "    print(f'{timestamp}')\n",
    "    print(f'{len(df)} results, saved as {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching r/rivian for \"broke down\"...\n",
      "Searching r/rivian for \"issue\"...\n",
      "Searching r/rivian for \"charging problem\"...\n",
      "Searching r/rivian for \"reliability\"...\n",
      "Searching r/rivian for \"won’t start\"...\n",
      "Searching r/electricvehicles for \"broke down\"...\n",
      "Searching r/electricvehicles for \"issue\"...\n",
      "Searching r/electricvehicles for \"charging problem\"...\n",
      "Searching r/electricvehicles for \"reliability\"...\n",
      "Searching r/electricvehicles for \"won’t start\"...\n",
      "Searching r/ElectricCars for \"broke down\"...\n",
      "Searching r/ElectricCars for \"issue\"...\n",
      "Searching r/ElectricCars for \"charging problem\"...\n",
      "Searching r/ElectricCars for \"reliability\"...\n",
      "Searching r/ElectricCars for \"won’t start\"...\n",
      "Reddit finished scraping\n",
      "20250711_022659\n",
      "0 results, saved as C:\\Users\\monke\\Repos\\eav-llm-monitor\\data\\raw\\reddit_raw_20250711_022659.csv\n"
     ]
    }
   ],
   "source": [
    "from utils import io_utils\n",
    "from utils import paths\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\" Praw resources\n",
    "https://praw.readthedocs.io/en/stable/index.html\n",
    "https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html\n",
    "https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html\n",
    "\"\"\"\n",
    "\n",
    "# praw setup\n",
    "reddit_creds = io_utils.read_json(reddit_creds_uri)\n",
    "reddit = praw.Reddit(\n",
    "    client_id = reddit_creds['REDDIT_CLIENT_ID'],\n",
    "    client_secret = reddit_creds['REDDIT_SECRET'],\n",
    "    user_agent = reddit_creds['REDDIT_USER_AGENT']\n",
    ")\n",
    "\n",
    "data_datetime_fmt = '%Y%m%d_%H%M%S'\n",
    "\n",
    "def scrape_reddit(subreddits, search_terms, last_update=None, limit=100):\n",
    "    \"\"\"Scrapes various subreddits for various terms and returns as a df\"\"\"\n",
    "    if last_update is None:\n",
    "        last_update = datetime(2005, 6, 23, 0, 0, 0) # beginning of reddit\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sub in subreddits:\n",
    "        for term in search_terms:\n",
    "            print(f'Searching r/{sub} for \"{term}\"...')\n",
    "            for post in reddit.subreddit(sub).search(term, sort='new', limit=limit):\n",
    "                post_timestamp = datetime.fromtimestamp(post.created_utc)\n",
    "                if post_timestamp > last_update:\n",
    "                    results.append({\n",
    "                        'subreddit': sub,\n",
    "                        'title': post.title,\n",
    "                        'selftext': post.selftext,\n",
    "                        'score': post.score,\n",
    "                        'created_utc': post_timestamp,\n",
    "                        'url': post.url,\n",
    "                        'permalink': f\"https://www.reddit.com{post.permalink}\"\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def find_latest_reddit_timestamp():\n",
    "    \"\"\"Find the latest timestamp from the reddit raw data files\"\"\"\n",
    "    latest_data_csv = [csv for csv in os.listdir(paths.get_data_raw_path()) if 'reddit' in csv]\n",
    "    if len(latest_data_csv) == 0:\n",
    "        return None\n",
    "    latest_data_csv = max(latest_data_csv)\n",
    "    datetime_str = latest_data_csv.replace('reddit_raw_','').replace('.csv', '')\n",
    "    return datetime.strptime(datetime_str, data_datetime_fmt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    subreddits = ['rivian', 'electricvehicles', 'ElectricCars']\n",
    "    subreddits += ['CarRepair', 'autorepair', 'MechanicAdvice']\n",
    "    subreddits += ['DIYAutoRepair', 'AutoMechanics']\n",
    "    \n",
    "    search_terms = ['broke down', 'issue', 'charging problem', 'reliability', 'won’t start']\n",
    "    \n",
    "    df = scrape_reddit(subreddits, search_terms, last_update = find_latest_reddit_timestamp())\n",
    "    \n",
    "    timestamp = datetime.now().strftime(data_datetime_fmt)\n",
    "    filename = paths.get_data_raw_path() / f'reddit_raw_{timestamp}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    print('Reddit finished scraping')\n",
    "    print(f'{timestamp}')\n",
    "    print(f'{len(df)} results, saved as {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monke\\\\Repos\\\\eav-llm-monitor\\\\notebooks'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/monke/Repos/eav-llm-monitor/notebooks')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-6082fd330492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "Path(__file__).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "        '\"electric vehicle\" reliability since:2024-01-01',\n",
    "        '\"rivian problem\" since:2024-01-01'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = '\"grok\"'\n",
    "encoded_query = search_term.replace(\" \", \"%20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://twitter.com/search?q={encoded_query}&src=typed_query&f=live\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "options = uc.ChromeOptions()\n",
    "options.headless = True\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--user-data-dir=/Users/monke/Library/Application Support/Google/Chrome\")  # or Windows equivalent\n",
    "options.add_argument(\"--profile-directory=Default\")  # or \"Profile 1\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/search?q=\"grok\"&src=typed_query&f=live'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \"electric vehicle\" reliability since:2024-01-01\n",
      "1 \"rivian problem\" since:2024-01-01\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(queries):\n",
    "    print(i, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape = sntwitter.TwitterSearchScraper(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22%5C%22rivian%20problem%5C%22%20since%3A2024-01-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22%5C%22rivian%20problem%5C%22%20since%3A2024-01-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22%5C%22rivian%20problem%5C%22%20since%3A2024-01-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6039526fcc42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     tweets.append({\n\u001b[0;32m      3\u001b[0m          \u001b[1;34m'date'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;34m'username'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;34m'content'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py\u001b[0m in \u001b[0;36mget_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1761\u001b[0m                 \u001b[0mpaginationParams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'variables'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpaginationVariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1763\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_api_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaginationParams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'search_by_raw_query'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'search_timeline'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'timeline'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'instructions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1764\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graphql_timeline_instructions_to_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search_by_raw_query'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search_timeline'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timeline'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instructions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py\u001b[0m in \u001b[0;36m_iter_api_data\u001b[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Retrieving scroll page {cursor}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m                         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_api_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapiType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreqParams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snscrape\\modules\\twitter.py\u001b[0m in \u001b[0;36m_get_api_data\u001b[1;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[0;32m    884\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mapiType\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquote_via\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apiHeaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_api_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapiType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapiType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_snscrapeObj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snscrape\\base.py\u001b[0m in \u001b[0;36m_get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snscrape\\base.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[0;32m    269\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Errors: {\", \".join(errors)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mScraperException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reached unreachable code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22%5C%22rivian%20problem%5C%22%20since%3A2024-01-01%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "for i, tweet in enumerate(scrape.get_items()):\n",
    "    tweets.append({\n",
    "         'date': tweet.date,\n",
    "        'username': tweet.user.username,\n",
    "        'content': tweet.content,\n",
    "        'url': tweet.url,\n",
    "        'id': tweet.id\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-57fc2c7c7187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
